{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShawnYu111/CV/blob/main/microbial_cv_(3).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install innvestigate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlDpBQ3UbzMx",
        "outputId": "98d42bb5-070e-4232-c69d-83022b81088e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting innvestigate\n",
            "  Downloading innvestigate-1.0.9-py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from innvestigate) (1.21.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from innvestigate) (3.1.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from innvestigate) (7.1.2)\n",
            "Collecting keras==2.2.4\n",
            "  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
            "\u001b[K     |████████████████████████████████| 312 kB 40.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from innvestigate) (0.16.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from innvestigate) (3.6.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from innvestigate) (1.4.1)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4->innvestigate) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4->innvestigate) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4->innvestigate) (1.15.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->innvestigate) (1.5.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->innvestigate) (57.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->innvestigate) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->innvestigate) (21.4.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->innvestigate) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->innvestigate) (8.12.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->innvestigate) (1.11.0)\n",
            "Installing collected packages: keras-applications, keras, innvestigate\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "tensorflow 2.8.0 requires keras<2.9,>=2.8.0rc0, but you have keras 2.2.4 which is incompatible.\u001b[0m\n",
            "Successfully installed innvestigate-1.0.9 keras-2.2.4 keras-applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==2.2.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKY9a1TgcM60",
        "outputId": "11e540ae-f613-4da6-d838-2018c075d23b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.21.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.2.4) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==1.13.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLgi3zYgcgEJ",
        "outputId": "9aa6fbd0-df5f-4673-81be-07043840e23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==1.13.1\n",
            "  Downloading tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 92.6 MB 57 kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.5.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 24.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.44.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.37.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.21.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.0.0)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n",
            "\u001b[K     |████████████████████████████████| 367 kB 29.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.17.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.10.0.2)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.1) (1.5.2)\n",
            "Installing collected packages: mock, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.13.1 which is incompatible.\u001b[0m\n",
            "Successfully installed mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DpL9OjmapCO",
        "outputId": "b1a64d3c-076a-4115-a3ac-2d64909255f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow version: 1.13.1\n",
            "keras version: 2.2.4\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "### Import Relevant Libraries\n",
        "'''\n",
        "import numpy as np # Version 1.16.0\n",
        "import tensorflow as tf # Version 1.12.0\n",
        "import pandas as pd\n",
        "import keras # Version 2.2.4\n",
        "from sklearn.metrics import r2_score\n",
        "import innvestigate as inn # Version 1.0.8\n",
        "print(\"tensorflow version:\", tf.__version__)\n",
        "print(\"keras version:\", keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHmPaUUyapCQ"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "### Read and Process Data\n",
        "'''\n",
        "# Load in raw count data for neural network\n",
        "X = pd.read_csv(\"X.csv\", index_col=0)\n",
        "# Load in ground truth methane production rate data\n",
        "y = pd.read_csv(\"Y.csv\", index_col=0)\n",
        "# Set parameters\n",
        "num_samples = X.shape[0]\n",
        "num_folds = 3 # Leave-one-out = 149\n",
        "num_features = 50 # All features = 489\n",
        "# Create linearly spaced chunks for cross validation\n",
        "chunks = np.ceil(np.linspace(0,num_samples, num=num_folds+1)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9Pl3S5ZapCQ"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "### Define and Compile Model\n",
        "'''\n",
        "def build_model(input_shape):\n",
        "    # Define model\n",
        "    model = keras.models.Sequential([\n",
        "            keras.layers.Conv1D(filters=128, kernel_size=1, activation='relu', input_shape=input_shape),\n",
        "            keras.layers.Conv1D(filters=128, kernel_size=1, activation='relu'),\n",
        "            keras.layers.Conv1D(filters=128, kernel_size=1, activation='relu'),\n",
        "            keras.layers.Dropout(0.1),\n",
        "            keras.layers.Conv1D(filters=128, kernel_size=1, activation='relu'),\n",
        "            keras.layers.Conv1D(filters=128, kernel_size=1, activation='relu'),\n",
        "            keras.layers.Conv1D(filters=128, kernel_size=1, activation='relu'),\n",
        "            keras.layers.Dropout(0.1),\n",
        "            keras.layers.Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "            keras.layers.Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "            keras.layers.Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "            keras.layers.Dropout(0.1),\n",
        "            keras.layers.Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "            keras.layers.Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "            keras.layers.Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "            keras.layers.Dropout(0.1),\n",
        "            keras.layers.Conv1D(filters=32, kernel_size=1, activation='relu'),\n",
        "            keras.layers.Conv1D(filters=32, kernel_size=1, activation='relu'),\n",
        "            keras.layers.Conv1D(filters=32, kernel_size=1, activation='relu'),\n",
        "            keras.layers.Dropout(0.1),\n",
        "            keras.layers.Conv1D(filters=32, kernel_size=1, activation='relu'),\n",
        "            keras.layers.Conv1D(filters=32, kernel_size=1, activation='relu'),\n",
        "            keras.layers.Conv1D(filters=32, kernel_size=1, activation='relu'),\n",
        "            keras.layers.Flatten(),\n",
        "            keras.layers.Dense(64, activation='relu'),\n",
        "            keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    # Compile Model\n",
        "    model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=0.001))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "f1AbeJ-QapCR"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "### Run Neural Network Cross Validation\n",
        "'''\n",
        "lrp_cache = pd.DataFrame()\n",
        "ann_predictions = np.array([])\n",
        "history_cache = []\n",
        "for fold in range(num_folds):\n",
        "\n",
        "    # Reset keras session to reduce model clutter\n",
        "    keras.backend.clear_session()\n",
        "\n",
        "    # Select validation samples\n",
        "    X_val = X[chunks[fold]:chunks[fold+1]]\n",
        "    y_val = y[chunks[fold]:chunks[fold+1]]\n",
        "    # Select training samples\n",
        "    X_train = X.drop(X_val.index)\n",
        "    y_train = y.drop(X_val.index).values.flatten()\n",
        "\n",
        "    # Feature selection using Layerwise Relevance Propegation (LRP)\n",
        "    # Build and train model for LRP\n",
        "    model = build_model((X_train.shape[1],1))\n",
        "    model.fit(np.expand_dims(X_train.values, axis=2), y_train, batch_size=32, epochs=15, verbose=0)\n",
        "    # Sort features by LRP Relevance Score\n",
        "    analyzer = inn.create_analyzer(\"lrp.z_plus_fast\", model)\n",
        "    # Perform backwards pass through trained neural network to generate relevance scores\n",
        "    scores = analyzer.analyze(np.expand_dims(X_train.values, axis=2))[...,0]\n",
        "    print(\"##################\")\n",
        "    print(scores.shape)\n",
        "    pd.DataFrame(scores).to_csv('score.csv',index=False)\n",
        "    print(\"##################\")\n",
        "    # Store data in Dataframe\n",
        "    lrp = pd.DataFrame(scores.mean(axis=0), index=X_train.columns, columns=[\"Score\"])\n",
        "    # Sort scores by absolute value\n",
        "    lrp[\"Abs Score\"] = np.abs(lrp[\"Score\"])\n",
        "    lrp_cache[fold] = lrp[\"Abs Score\"]\n",
        "    lrp.sort_values(by=\"Abs Score\", ascending=False, inplace=True)\n",
        "\n",
        "    # Select most important features\n",
        "    X_train = X_train[lrp.index[:num_features]]\n",
        "    X_val = X_val[lrp.index[:num_features]]\n",
        "\n",
        "    # Reshape data for nerual network\n",
        "    X_train = np.asarray(X_train).reshape((X_train.shape[0],X_train.shape[1],1))\n",
        "    X_val = np.asarray(X_val).reshape((X_val.shape[0],X_val.shape[1],1))\n",
        "\n",
        "    # Run neural network model\n",
        "    model = build_model((X_train.shape[1],1))\n",
        "    history = model.fit(X_train, y_train, batch_size=32, epochs=15, verbose=0, validation_data=(X_val, y_val))\n",
        "\n",
        "    # Cache prediction values to array\n",
        "    predictions = model.predict(X_val).flatten()\n",
        "    ann_predictions = np.concatenate([ann_predictions, predictions])\n",
        "    history_cache.append(history)\n",
        "\n",
        "    # Print status update\n",
        "    print(\"--------[{}/{}]--------\".format(fold+1, num_folds))\n",
        "    for i in range(chunks[fold+1] - chunks[fold]):\n",
        "        print(\"Validation Sample:\", y.index.values[chunks[fold]+i])\n",
        "        print(\"ANN Prediction: {:.5f}\".format(ann_predictions[chunks[fold]+i]))\n",
        "        print(\"Ground Truth: {:.5f}\\n\".format(y.values.flatten()[chunks[fold]+i]))\n",
        "\n",
        "# Print results\n",
        "print(\"\\nCross Validation Results:\\n\")\n",
        "ann_r2 = r2_score(y, ann_predictions)\n",
        "print(\"Neural Network R2 Score: {:.5f}\".format(ann_r2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = pd.DataFrame(scores)\n",
        "scores.to_csv('score.csv',index=False)\n",
        "lrp.to_csv('lrp.csv',index=True)"
      ],
      "metadata": {
        "id": "IA2NYih9faH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw5JoaQoUivB",
        "outputId": "9b743d05-e4f0-4bf4-ca14-181a76d06cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(149, 489)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X.drop(X.tail(50).index,inplace=True)\n",
        "X.drop(X.head(99).index,inplace=True)\n",
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV81se32UOp1",
        "outputId": "c7275d00-e52f-47ed-adf0-4b1f05b40eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 489)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNNG0iGVapCR"
      },
      "outputs": [],
      "source": [
        "model = build_model((X.shape[1],1))\n",
        "model.fit(np.expand_dims(X.values, axis=2), y, batch_size=32, epochs=15, verbose=0)\n",
        "analyzer = inn.create_analyzer(\"lrp.z_plus_fast\", model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = analyzer.analyze(np.expand_dims(X.values, axis=2))[...,0]\n",
        "lrp = pd.DataFrame(scores.mean(axis=0), index=X.columns, columns=[\"Score\"])\n",
        "# Sort scores by absolute value\n",
        "lrp[\"Abs Score\"] = np.abs(lrp[\"Score\"])\n",
        "#lrp_cache[fold] = lrp[\"Abs Score\"]\n",
        "lrp.sort_values(by=\"Abs Score\", ascending=False, inplace=True)\n",
        "lrp.to_csv(\"lrp.csv\",index=True)"
      ],
      "metadata": {
        "id": "7g89kVC4Uswl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}